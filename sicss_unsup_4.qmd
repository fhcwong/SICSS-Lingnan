---
title: "sicss_unsup_4"
date: June 18, 2025
instructor: Frankie Ho Chun WONG
---

## Embeddings

This demo shows the basic steps to produce text embeddings. Vectors obtained from this process can be fed into other NLP tasks.

```{r}
Sys.setLanguage("en")
```

**Install the packages (for the first time)**

```{r}
install.packages("word2vec")
install.packages("data.table")
install.packages("stringr")
install.packages("dplyr")
install.packages("tidytext")
install.packages("tidyr")
install.packages("readxl")
install.packages("ggplot2")
install.packages("ggrepel")
install.packages("plotly")
install.packages("umap")
install.packages("quanteda")
install.packages("quanteda.textstats")
```

**Load packages**

```{r}
library("word2vec")
library("data.table")
library("stringr")
library("dplyr")
library("tidytext")
library("tidyr")
library("readxl")
library("ggplot2")
library("ggrepel")
library("plotly")
library("umap")
library("quanteda")
library("quanteda.textstats")
```

#Begin

**Obtain sample data**

```{r}
dat <- read_excel("demo_rss_world_news_mar2025.xlsx")
head(dat) #same as head(attributes(data)$docvar)
```

```{r}
dat_gua <- subset.data.frame(dat, dat$source=="The Guardian")
dat_tass <- subset.data.frame(dat, dat$source=="TASS")
```

Obtain the text from dataframe and remove punctuation

```{r}
news_items <- dat_gua$text
news_items <- gsub("[][!#$%()*,.:;<=>@^_|~.{}]“”", "", news_items)
```

**Create a word2vec model with a Continuous Bag of Words (CBOW) approach**

Parameters for building the model are:

"type": the algorithm

"dim": dimensions in the model

"window": window between target word

"iter": iterations of the process

Read more: <https://www.geeksforgeeks.org/word2vec-using-r/>

```{r}
cbow_model <- word2vec(x = news_items, type = "cbow", dim = 30, iter = 20, window = 5, stopwords = stopwords("english"))
```

Find similar words from the model

```{r}
predict(cbow_model, c("government", "people"), type = "nearest", top_n = 5)
```

Export the embeddings

```{r}
cbow_embedding <- as.matrix(cbow_model)
as.data.frame(cbow_embedding)
```

**Create a word2vec model with a skip gram approach**

```{r}
sg_model <- word2vec(x = news_items, type = "skip-gram", dim = 30, iter = 20, window = 5, stopwords = stopwords("english"))
```

Similarly, find similar words

```{r}
predict(sg_model, c("government", "people"), type = "nearest", top_n = 10)
```

Export the embeddings in the same way

```{r}
sg_embedding <- as.matrix(sg_model)
as.data.frame(sg_embedding)
```

### Visualization

Obtain the frequent words from data

```{r}
#define the number of frequent words to be visualized 
freqwords <- 100

freq_dat <- corpus(dat, text_field = "text")|>
    tokens(remove_punct = TRUE) |>
    tokens_remove(pattern = stopwords('english')) |>
    dfm() |>
    dfm_trim(min_termfreq = 10, verbose = FALSE)|>
    textstat_frequency(n = freqwords)
word_list <- freq_dat$feature
```

#### Embeddings of the wordlist

Obtain the vectors for visualization

```{r}
embedding_pred <- predict(cbow_model, word_list, type = "embedding") |>na.omit()
```

UMAP for dimension reduction

"n_components" for the number of dimensions to be reduced

```{r}
#number of dimensions
n_dim <- 2

#dimension reduction
vizualization <- umap(embedding_pred, n_neighbors = 15, n_threads = 2,n_components=n_dim)

```

```{r}
#select the dimensions to be visualized 
x_dim <- 1
y_dim <- 2

#build the df for visualization 
embedding_vis <- data.frame(word = rownames(embedding_pred), 
                xpos = gsub(".+//", "", rownames(embedding_pred)), 
                x = vizualization$layout[, x_dim], 
                y = vizualization$layout[, y_dim], 
                  stringsAsFactors = FALSE)

#visualize 
plot_ly(embedding_vis, x = ~x, y = ~y, type = "scatter", mode = 'text', text = ~word) |>  
  layout(title = "Embeddings Visualization")
```

Bonus: Visualize 3D

```{r}
#number of dimensions
n_dim <- 3

#dimension reduction
vizualization <- umap(embedding_pred, n_neighbors = 15, n_threads = 2,n_components=n_dim)

#select the dimensions to be visualized 
x_dim <- 1
y_dim <- 2
z_dim <- 3

#build the df for visualization 
embedding_vis <- data.frame(word = rownames(embedding_pred), 
                xpos = gsub(".+//", "", rownames(embedding_pred)), 
                x = vizualization$layout[, x_dim], 
                y = vizualization$layout[, y_dim], 
                z = vizualization$layout[, z_dim], 
                  stringsAsFactors = FALSE)

#visualize 
plot_ly(embedding_vis, x = ~x, y = ~y, z = ~z, type = "scatter3d", mode = 'text', text = ~word) |>  
  layout(title = "CBOW Embeddings Visualization")
```

**\#**END
